{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYSGdczzCnhR5cfWpFfr+e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harmonydata/experiments/blob/main/harmony_wmd_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Word Movers Distance to Harmony\n",
        "\n",
        "See paper: Kusner, Matt, et al. \"From word embeddings to document distances.\" International conference on machine learning. PMLR, 2015.\n",
        "\n",
        "https://www.cs.cornell.edu/~kilian/papers/wmd_metric.pdf\n",
        "\n",
        "\n",
        "Can Harmony show a distance metric between two instruments?\n",
        "\n",
        "Each instrument is a sequence of sentence embeddings.\n",
        "\n",
        "The distance between two sentence embeddings is given by the cosine similarity function which Harmony is already using.\n",
        "\n",
        "But the distance between two **sequences** of embeddings?\n",
        "\n",
        "The Word Movers Distance algorithm might help!\n",
        "\n",
        "Code from **Eve Cheng**'s branch and pull request, https://github.com/EveWCheng/harmony/blob/main/src/harmony/matching/wmd_matcher.py"
      ],
      "metadata": {
        "id": "Vr5DqCM6Ugni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wmd\n",
        "!pip install harmonydata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ciKRpiUTRMz",
        "outputId": "a0bff222-e5d2-48ab-80e7-9ede5335e391"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wmd\n",
            "  Downloading wmd-1.3.2.tar.gz (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from wmd) (1.25.2)\n",
            "Building wheels for collected packages: wmd\n",
            "  Building wheel for wmd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wmd: filename=wmd-1.3.2-cp310-cp310-linux_x86_64.whl size=1150986 sha256=230eb31372332abc8eb975655ea8956296fdb3e59be165dfd7388feac61bcccc\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/09/7f/ebf39133074a0411263ce255a480293fb2e91bceaeed6a4141\n",
            "Successfully built wmd\n",
            "Installing collected packages: wmd\n",
            "Successfully installed wmd-1.3.2\n",
            "Collecting harmonydata\n",
            "  Downloading harmonydata-0.5.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic==1.10.7 (from harmonydata)\n",
            "  Downloading pydantic-1.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==2.0.0 (from harmonydata)\n",
            "  Downloading pandas-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tika==2.6.0 (from harmonydata)\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lxml==4.9.2 (from harmonydata)\n",
            "  Downloading lxml-4.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect==1.0.9 (from harmonydata)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting XlsxWriter==3.0.9 (from harmonydata)\n",
            "  Downloading XlsxWriter-3.0.9-py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openpyxl==3.1.2 in /usr/local/lib/python3.10/dist-packages (from harmonydata) (3.1.2)\n",
            "Collecting spacy==3.5.3 (from harmonydata)\n",
            "  Downloading spacy-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wget==3.2 (from harmonydata)\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentence-transformers==2.2.2 (from harmonydata)\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect==1.0.9->harmonydata) (1.16.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl==3.1.2->harmonydata) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.0->harmonydata) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.0->harmonydata) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.0->harmonydata) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.0->harmonydata) (1.25.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==1.10.7->harmonydata) (4.10.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->harmonydata) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->harmonydata) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->harmonydata) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->harmonydata) (0.17.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->harmonydata) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->harmonydata) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->harmonydata) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->harmonydata) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2->harmonydata) (0.20.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->harmonydata) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->harmonydata) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->harmonydata) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->harmonydata) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->harmonydata) (3.0.9)\n",
            "Collecting thinc<8.2.0,>=8.1.8 (from spacy==3.5.3->harmonydata)\n",
            "  Downloading thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m919.6/919.6 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->harmonydata) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->harmonydata) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->harmonydata) (2.0.10)\n",
            "Collecting typer<0.8.0,>=0.3.0 (from spacy==3.5.3->harmonydata)\n",
            "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
            "Collecting pathy>=0.10.0 (from spacy==3.5.3->harmonydata)\n",
            "  Downloading pathy-0.11.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->harmonydata) (6.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->harmonydata) (2.31.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->harmonydata) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->harmonydata) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->harmonydata) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy==3.5.3->harmonydata) (3.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2->harmonydata) (3.13.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2->harmonydata) (2023.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2->harmonydata) (6.0.1)\n",
            "Collecting pathlib-abc==0.1.1 (from pathy>=0.10.0->spacy==3.5.3->harmonydata)\n",
            "  Downloading pathlib_abc-0.1.1-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.3->harmonydata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.3->harmonydata) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.3->harmonydata) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.5.3->harmonydata) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy==3.5.3->harmonydata) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy==3.5.3->harmonydata) (0.1.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2->harmonydata) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2->harmonydata) (3.2.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers==2.2.2->harmonydata)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers==2.2.2->harmonydata)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers==2.2.2->harmonydata)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6.0->sentence-transformers==2.2.2->harmonydata)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6.0->sentence-transformers==2.2.2->harmonydata)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6.0->sentence-transformers==2.2.2->harmonydata)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6.0->sentence-transformers==2.2.2->harmonydata)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6.0->sentence-transformers==2.2.2->harmonydata)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6.0->sentence-transformers==2.2.2->harmonydata)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.6.0->sentence-transformers==2.2.2->harmonydata)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers==2.2.2->harmonydata)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2->harmonydata) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence-transformers==2.2.2->harmonydata)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2->harmonydata) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2->harmonydata) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2->harmonydata) (0.4.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy==3.5.3->harmonydata) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy==3.5.3->harmonydata) (2.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2->harmonydata) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.2.2->harmonydata) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers==2.2.2->harmonydata) (9.4.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2->harmonydata) (1.3.0)\n",
            "Building wheels for collected packages: langdetect, sentence-transformers, tika, wget\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993227 sha256=93ab10be34be8a17f15e4bc406dac13515d450272532bcec23a983beb7e86f39\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125924 sha256=33ddbabc75589851cb80a213d1807bef06cb1b5ca0bbd3f19537df4003feed15\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32621 sha256=5d6485049fdfd6e248cacb7218394faae302de2e80c06b08667e2d6e299dd46f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=5b858e162b3a709828798c6e22697e1732a8494bc59d290613792ecf77c0bbb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built langdetect sentence-transformers tika wget\n",
            "Installing collected packages: wget, XlsxWriter, typer, pydantic, pathlib-abc, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lxml, langdetect, tika, pathy, pandas, nvidia-cusparse-cu12, nvidia-cudnn-cu12, thinc, nvidia-cusolver-cu12, spacy, sentence-transformers, harmonydata\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.6.4\n",
            "    Uninstalling pydantic-2.6.4:\n",
            "      Successfully uninstalled pydantic-2.6.4\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.9.4\n",
            "    Uninstalling lxml-4.9.4:\n",
            "      Successfully uninstalled lxml-4.9.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.2.3\n",
            "    Uninstalling thinc-8.2.3:\n",
            "      Successfully uninstalled thinc-8.2.3\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.7.4\n",
            "    Uninstalling spacy-3.7.4:\n",
            "      Successfully uninstalled spacy-3.7.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.5.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed XlsxWriter-3.0.9 harmonydata-0.5.2 langdetect-1.0.9 lxml-4.9.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pandas-2.0.0 pathlib-abc-0.1.1 pathy-0.11.0 pydantic-1.10.7 sentence-transformers-2.2.2 spacy-3.5.3 thinc-8.1.12 tika-2.6.0 typer-0.7.0 wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qNap8CTrUf7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wmd import WMD\n",
        "import numpy as np\n",
        "import math\n",
        "import libwmdrelax\n",
        "\n",
        "def euclidean_dist(point1, point2):\n",
        "    if len(point1) != len(point2):\n",
        "        raise ValueError(\"Points must have the same number of dimensions\")\n",
        "\n",
        "    squared_distance = sum((p1 - p2) ** 2 for p1, p2 in zip(point1, point2))\n",
        "    distance = math.sqrt(squared_distance)\n",
        "    return distance\n",
        "\n",
        "def par_to_vecs(par,vectorisation_function):\n",
        "    return [vectorisation_function(sent) for sent in par]\n",
        "\n",
        "def dist(vecs1,vecs2):\n",
        "    vec_union = list(vecs1 + vecs2)\n",
        "    n1,n2 = len(vecs1),len(vecs2)\n",
        "    n = len(vec_union)\n",
        "    dist_ = np.zeros((n,n))\n",
        "    for i in range(n):\n",
        "        for j in range(i):\n",
        "            dist_[i,j] = dist_[j,i] = euclidean_dist(vec_union[i],vec_union[j])\n",
        "\n",
        "    nw1 = [1. for i in range(n1)]+[0. for i in range(n2)]\n",
        "    nw2 = [0. for i in range(n1)] +[1. for i in range(n2)]\n",
        "    return np.array(dist_,dtype=np.float32),np.array(nw1,dtype=np.float32),np.array(nw2,dtype=np.float32)\n",
        "\n",
        "\n",
        "def pars_dist_emd_emdrelaxed(par1,par2,vectorisation_function):\n",
        "    relax_cache = libwmdrelax.emd_relaxed_cache_init(int(100))\n",
        "    cache = libwmdrelax.emd_cache_init(int(100))\n",
        "\n",
        "    vecs1,vecs2 = par_to_vecs(par1,vectorisation_function),par_to_vecs(par2,vectorisation_function)\n",
        "    dist_,nw1,nw2 = dist(vecs1,vecs2)\n",
        "    emd = libwmdrelax.emd(nw1,nw2,dist_,cache)\n",
        "    emd_relaxed = libwmdrelax.emd_relaxed(nw1,nw2,dist_,relax_cache)\n",
        "    return emd,emd_relaxed\n"
      ],
      "metadata": {
        "id": "eJKmRUENTcE6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "USETxRGvTHYt"
      },
      "outputs": [],
      "source": [
        "import harmony\n",
        "import numpy as np\n",
        "from harmony import match_instruments\n",
        "import json\n",
        "from wmd import WMD\n",
        "\n",
        "def texts_similarity_matrix_benchmark(text_vectors):\n",
        "        # Create numpy array of texts vectors\n",
        "        # Get similarity with polarity\n",
        "        vectors_pos,vectors_neg = harmony.matching.matcher.vectors_pos_neg(text_vectors)\n",
        "        if vectors_pos.any():\n",
        "            pos_pairwise_similarity = harmony.matching.matcher_utils.cosine_similarity(vectors_pos, vectors_pos)\n",
        "        return pos_pairwise_similarity\n",
        "\n",
        "def test_similarity():\n",
        "    questions = [\"I was bothered by things that usually don’t bother me.\",\"I did not feel like eating; my appetite was poor.\",\"I felt that I could not shake off the blues even with help from my family or friends.\",\"I felt I was just as good as other people.\"]\n",
        "    questions = [\"lost my key\", \"found my car\"]\n",
        "    vectorisation_function = harmony.matching.default_matcher.convert_texts_to_vector\n",
        "    text_vectors = harmony.matching.matcher.process_questions(questions)\n",
        "    print(text_vectors)\n",
        "    text_vectors = harmony.matching.matcher.vectorise_texts(text_vectors,vectorisation_function)\n",
        "    print(texts_similarity_matrix_benchmark(text_vectors))\n",
        "#   pip install harmonydata\n",
        "\n",
        "def test_match_instruments_with_function():\n",
        "    instruments = harmony.example_instruments[\"CES_D English\"], harmony.example_instruments[\"GAD-7 Portuguese\"]\n",
        "    print(instruments[0])\n",
        "    query = \"Lost much sleep over worry?\"\n",
        "    vectorisation_function = harmony.matching.default_matcher.convert_texts_to_vector\n",
        "    all_questions, similarity_with_polarity, query_similarity, new_vectors_dict=harmony.matching.matcher.match_instruments_with_function(instruments[1:10],query,vectorisation_function,[],[],np.zeros((0, 0)),{})\n",
        "    print(all_questions)\n",
        "    print(similarity_with_polarity)\n",
        "#    print(query_similarity)\n",
        "#    print(new_vectors_dict)\n",
        "    np.savetxt(\"sim_with_polarity.txt\", similarity_with_polarity, fmt='%d', delimiter='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorisation_function = harmony.matching.default_matcher.convert_texts_to_vector\n",
        "par1 = [\"I want to go outside\",\"oh outside is nice\"]\n",
        "par2 = [\"I want to go outside maybe\",\"oh outside is nice\"]\n",
        "par3 = [\"You are a dog\", \"I love dogs\"]\n",
        "par4 = [\"I am sad\",\"are you sad\"]\n",
        "\n",
        "print (\"Comparing two sequences to itself\")\n",
        "\n",
        "emd,emd_relaxed = pars_dist_emd_emdrelaxed(par1, par1,vectorisation_function)\n",
        "print(emd)\n",
        "print(emd_relaxed)\n",
        "\n",
        "print (\"Comparing\", par4, par3)\n",
        "\n",
        "emd,emd_relaxed = pars_dist_emd_emdrelaxed(par4,par3,vectorisation_function)\n",
        "print(emd)\n",
        "print(emd_relaxed)\n",
        "\n",
        "print (\"Comparing\", par1, par3)\n",
        "\n",
        "emd,emd_relaxed = pars_dist_emd_emdrelaxed(par1,par3,vectorisation_function)\n",
        "print(emd)\n",
        "print(emd_relaxed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRimADQbTRVz",
        "outputId": "f2b076f0-88a8-4ad5-9230-a6da81e94132"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparing two sequences to itself\n",
            "0.0\n",
            "0.0\n",
            "Comparing ['I am sad', 'are you sad'] ['You are a dog', 'I love dogs']\n",
            "12.535743713378906\n",
            "12.53574275970459\n",
            "Comparing ['I want to go outside', 'oh outside is nice'] ['You are a dog', 'I love dogs']\n",
            "13.033099174499512\n",
            "13.033098220825195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gag1GiQ8TJVT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}